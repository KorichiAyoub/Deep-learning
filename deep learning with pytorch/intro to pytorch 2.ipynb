{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "#create a network class to reuse\n",
    "class Net( nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9,10)\n",
    "        self.fc2 = nn.Linear(16,8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=nn.functional.relu(self.fc1(x))\n",
    "        x=nn.functional.relu(self.fc2(x))\n",
    "        x=nn.functional.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "class WaterDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        super().__init__()\n",
    "        # Load data to pandas DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "        # Convert data to a NumPy array and assign to self.data\n",
    "        self.data = df.to_numpy()\n",
    "        \n",
    "    # Implement __len__ to return the number of data samples\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.data[idx, :-1]\n",
    "        # Assign last data column to label\n",
    "        label = self.data[idx,-1]\n",
    "        return features, label\n",
    "    \n",
    "\n",
    "dataset = WaterDataset('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]]) tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Create a DataLoader based on dataset_train\n",
    "dataloader_train = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Get a batch of features and labels\n",
    "features, labels = next(iter(dataloader_train))\n",
    "print(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adagrad(net.parameters(),lr=0.01)# it addapts the lr\n",
    "# but it may decrease the lr too fast \n",
    "optimizer2 = optim.RMSprop(net.parameters(),lr=0.01)# updates the lr based on the previous gradient\n",
    "optimizer3 = optim.Adam(net.parameters(),lr=0.01) # RMSprop + gradient momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vanishing gradients : when gradeints get really small and prevent model from training\n",
    "- exploding gradients : when gradients gets bigger so training diverges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a way to deal with this is initialize the weights in a way that:\n",
    "- variance of layer inputs = var outputs\n",
    "- variance of gradients the same before and after a layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.init as init\n",
    "#create a network class to reuse\n",
    "class Net( nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9,10)\n",
    "        self.fc2 = nn.Linear(16,8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "\n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(self.fc3.weight,\n",
    "                            nonlinearity=\"sigmoid\"\n",
    "                            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=nn.functional.relu(self.fc1(x))\n",
    "        x=nn.functional.relu(self.fc2(x))\n",
    "        x=nn.functional.sigmoid(self.fc3(x))\n",
    "        # nn.functional.elu helps againts dying neurons\n",
    "        return x\n",
    "    \n",
    "net = Net() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch normalisation : normalizing the output of an activation layer with mean and std of a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net( nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(9,10)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "        self.fc2 = nn.Linear(16,8)\n",
    "        self.fc3 = nn.Linear(8,1)\n",
    "\n",
    "        init.kaiming_uniform_(self.fc1.weight)\n",
    "        init.kaiming_uniform_(self.fc2.weight)\n",
    "        init.kaiming_uniform_(self.fc3.weight,\n",
    "                            nonlinearity=\"sigmoid\"\n",
    "                            )\n",
    "        def forward(self,x):\n",
    "            x = self.fc1(x)\n",
    "            x=nn.functional.bn1(x)\n",
    "            x=nn.functional.relu(x)\n",
    "            # ...\n",
    "            return x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "train_trainsforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64,64))\n",
    "])\n",
    "dataset_train = ImageFolder(\n",
    "    \"./clouds/clouds/clouds_train\",\n",
    "    transform=train_trainsforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    shuffle=True,batch_size=1\n",
    ")\n",
    "\n",
    "image,label =next(iter(dataloader_train))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 for batch size \n",
    "\n",
    "3 for the colors \n",
    "\n",
    "128 ,128 for height and weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 3])\n"
     ]
    }
   ],
   "source": [
    "# to print it \n",
    "image=image.squeeze().permute(1,2,0)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in data augmentation we apply random tranformation to the images to get more data like rotation fliping ..\n",
    "\n",
    "makes the model more robust to changes and variations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainsforms=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomAutocontrast(),\n",
    "        transforms.ToTensor(),\n",
    "    transforms.Resize((128,128))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but we usually dont use linear layer because the number of parameters will explose \n",
    " - let say we have a 256*256 image if we put a layer of neuroons with 1000 that will be over 65M parameter\n",
    "\n",
    "so use filters instead or convolution layers\n",
    "\n",
    "a convolution is a the dot product betw input patch and a filter \n",
    "\n",
    "we often add padding of zeros to our patch to prevent loss, it ensures that the pixels at the border receive as much attention as those located elsewhere in the feature map.\n",
    "\n",
    "max polling : it's got by sliding non overlaping window and take max in that window\n",
    "\n",
    "Convolutional layers preserve spatial information between their inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):                                                               \n",
    "        super().__init__() # image start with 3*64*64 our data \n",
    "        self.feature_extractor = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, padding=1),#32*64*64\n",
    "        nn.ELU(),\n",
    "        nn.MaxPool2d(kernel_size=2),#32*32*32\n",
    "        nn.Conv2d(32, 64, kernel_size=3, padding=1),#64*32*32\n",
    "        nn.ELU(),\n",
    "        nn.MaxPool2d(kernel_size=2),#64*16*16\n",
    "        nn.Flatten(),#flattening the output to array of vals\n",
    "        )\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)                                                             \n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data augmentation can sometimes impact the label for example flipping w vertically will make it M\n",
    "- chaging color of orange to yellow will make look like lemmon but label is still orange "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 1.808331892263726\n",
      "epoch loss: 1.4407416514950149\n",
      "epoch loss: 1.1820825186976143\n",
      "epoch loss: 0.9155437285609969\n",
      "epoch loss: 0.6789381928265741\n",
      "epoch loss: 0.39258361237196077\n",
      "epoch loss: 0.4155151549273603\n",
      "epoch loss: 0.31000139583146474\n",
      "epoch loss: 0.1663721809213658\n",
      "epoch loss: 0.03888564835041043\n"
     ]
    }
   ],
   "source": [
    "net = Net(num_classes=7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)\n",
    "for epoch in range(10):\n",
    "    epoch_loss = 0\n",
    "    for images,labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        epoch_loss+=loss.item()\n",
    "        optimizer.step()\n",
    "    print(\"epoch loss:\",epoch_loss/len(dataloader_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    # no data augmentation in test\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64,64))\n",
    "])\n",
    "\n",
    "dataset_test = ImageFolder(\n",
    "    './clouds/clouds/clouds_test',\n",
    "    transform=test_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x256 and 16384x7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 3\u001b[0m     test_output \u001b[38;5;241m=\u001b[39m net(image)  \u001b[38;5;66;03m# Make sure to add an extra dimension for batch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     _, predicted_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(test_output, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_class\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 18\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(x)                                                             \n\u001b[1;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x256 and 16384x7)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
